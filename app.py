import streamlit as st
import google.generativeai as genai

# âœ… Configure Gemini API
api_key = st.secrets["GEMINI_API_KEY"]  # or use st.secrets or os.getenv
genai.configure(api_key=api_key)

# âœ… Load Gemini model (You can also use: "gemini-1.5-flash" or "gemini-pro")
model = genai.GenerativeModel("gemini-2.0-flash-lite")

# âœ… Set Streamlit Page Config
st.set_page_config(page_title="ğŸ¤– Agent Ramana", page_icon="ğŸ¤–", layout="wide")

# âœ… Add basic CSS for style
st.markdown(
    """
   <style>
    .chat-container {
        display: flex;
        margin-bottom: 10px;
    }
    .user-msg {
        background-color: #2563eb;
        color: white;
        border-radius: 12px;
        padding: 12px;
        max-width: 70%;
        margin-left: auto;
        text-align: right;
    }
    .ai-msg {
        background-color: #f3f4f6;
        color: #22223b;
        border-radius: 12px;
        padding: 12px;
        max-width: 70%;
        margin-right: auto;
        text-align: left;
    }
    </style>
    """,
    unsafe_allow_html=True
)

st.title("ğŸ¤– Agent Ramana")

# âœ… Initialize message history
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "ai",
            "content": (
                "Hey, I'm Ramana â€” your friendly personal companion ğŸ¤—. "
                "You can share anything with me â€” your thoughts, dreams, problems, or just chat casually. "
                "I'm always here to listen and talk like a friend ğŸ’¬"
            )
        }
    ]

# âœ… Display previous messages
for msg in st.session_state.messages:
    css_class = "user" if msg["role"] == "user" else "ai"
    st.markdown(f'<div class="stChatMessage {css_class}">{msg["content"]}</div>', unsafe_allow_html=True)

# âœ… User input
user_input = st.chat_input("Type your message and press Enter", key="input")

# âœ… Handle new user message
if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    st.rerun()

# âœ… Generate Gemini response only if last message is from user
if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    # Format history for Gemini
    chat_history = []
    for msg in st.session_state.messages:
        if msg["role"] == "user":
            chat_history.append({"role": "user", "parts": [msg["content"]]})
        else:
            chat_history.append({"role": "model", "parts": [msg["content"]]})

    # Get Gemini's reply
    try:
        response = model.generate_content(chat_history)
        ai_response = response.text
    except Exception as e:
        ai_response = f"âš ï¸ Error: {e}"

    # Store response
    st.session_state.messages.append({"role": "ai", "content": ai_response})
    st.rerun()
